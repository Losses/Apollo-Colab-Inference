{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8NuwnC--VPO4"
      },
      "outputs": [],
      "source": [
        "#@markdown #Install\n",
        "%cd /content/\n",
        "!git clone https://github.com/JusperLee/Apollo.git && cd Apollo\n",
        "\n",
        "!mkdir /content/Apollo/model\n",
        "%cd /content/Apollo/model\n",
        "!wget https://huggingface.co/JusperLee/Apollo/resolve/main/pytorch_model.bin\n",
        "\n",
        "!rm -rf '/content/Apollo/inference.py'\n",
        "%cd /content/Apollo\n",
        "!wget 'https://raw.githubusercontent.com/jarredou/Apollo-Colab-Inference/main/inference.py'\n",
        "\n",
        "!pip install omegaconf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xFqIYcKxVXyd"
      },
      "outputs": [],
      "source": [
        "%cd /content/Apollo\n",
        "#@markdown #Inference\n",
        "input_file_path = '/content/input.wav' #@param {type:\"string\"}\n",
        "output_file_path = '/content/output.wav' #@param {type:\"string\"}\n",
        "chunk_size = 30 #@param {type:\"slider\", min:5, max:50, step:5}\n",
        "\n",
        "!python inference.py \\\n",
        "    --in_wav '{input_file_path}' \\\n",
        "    --out_wav '{output_file_path}' \\\n",
        "    --chunk_size {chunk_size}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
