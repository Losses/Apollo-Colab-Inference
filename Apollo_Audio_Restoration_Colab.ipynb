{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-_VkjEtMvc5"
      },
      "source": [
        "[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/Q5Q811R5YI)  \n",
        "# Apollo-Colab-Inference (Batch Processing Version) [![Open In Github](https://img.shields.io/badge/github-code-green)](https://github.com/jarredou/Apollo-Colab-Inference/)  \n",
        "\n",
        "*Original work [Apollo: Band-sequence Modeling for High-Quality Music Restoration in Compressed Audio](https://github.com/JusperLee/Apollo)*  \n",
        "\n",
        "The model was trained to restore/enhance lossy mp3 audio with bitrate <= 128 kbps.  \n",
        "___  \n",
        "### Refactored for Batch Processing:\n",
        "This notebook has been modified to process all audio files in an input directory and save them to an output directory, with logging for each file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8NuwnC--VPO4"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "#@markdown # 1. Install Dependencies & Setup Environment\n",
        "%cd /content/\n",
        "print(\"Cloning repository...\")\n",
        "!git clone https://github.com/JusperLee/Apollo.git && cd Apollo\n",
        "\n",
        "print(\"Creating model and config directories...\")\n",
        "!mkdir -p /content/Apollo/model /content/Apollo/configs\n",
        "\n",
        "print(\"Downloading models...\")\n",
        "%cd /content/Apollo/model\n",
        "!wget -q 'https://huggingface.co/JusperLee/Apollo/resolve/main/pytorch_model.bin'\n",
        "!wget -q 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model.ckpt'\n",
        "!wget -q 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model_v2.ckpt'\n",
        "!wget -q 'https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/apollo_model_uni.ckpt'\n",
        "\n",
        "print(\"Downloading config files...\")\n",
        "%cd /content/Apollo/configs\n",
        "!wget -q 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/config_apollo_vocal.yaml'\n",
        "!wget -q 'https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/config_apollo_uni.yaml'\n",
        "\n",
        "print(\"Updating inference script...\")\n",
        "%cd /content/Apollo\n",
        "!rm -f '/content/Apollo/inference.py'\n",
        "!wget -q 'https://raw.githubusercontent.com/jarredou/Apollo-Colab-Inference/main/inference.py'\n",
        "\n",
        "print(\"Installing required python packages...\")\n",
        "!pip install omegaconf ml_collections\n",
        "\n",
        "print(\"Creating default input and output directories...\")\n",
        "!mkdir -p /content/input_audio /content/output_audio\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xFqIYcKxVXyd"
      },
      "outputs": [],
      "source": [
        "#@markdown # 2. Run Inference on a Directory\n",
        "#@markdown ### ‚Üì Upload your audio files to the `input_directory` before running.\n",
        "import os\n",
        "import glob\n",
        "import shlex\n",
        "from IPython.display import clear_output\n",
        "\n",
        "input_directory = '/content/input_audio' #@param {type:\"string\"}\n",
        "output_directory = '/content/output_audio' #@param {type:\"string\"}\n",
        "model = 'Lew Universal Lossy Enhancer' #@param ['MP3 Enhancer', 'Lew Vocal Enhancer', 'Lew Vocal Enhancer v2 (beta)', 'Lew Universal Lossy Enhancer']\n",
        "#@markdown --- \n",
        "#@markdown #### Advanced Settings\n",
        "#@markdown *For the 'Lew Universal' model, set `chunk_size` to **19**. For all other models, **25** is recommended.*\n",
        "chunk_size = 19 #@param {type:\"slider\", min:3, max:25, step:1}\n",
        "overlap = 2 #@param {type:\"slider\", min:2, max:10, step:1}\n",
        "\n",
        "# Set current directory to the Apollo project folder\n",
        "%cd /content/Apollo\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# --- Model and Config Selection ---\n",
        "if model == 'MP3 Enhancer':\n",
        "    ckpt = '/content/Apollo/model/pytorch_model.bin'\n",
        "    config = 'configs/apollo.yaml'\n",
        "elif model == 'Lew Vocal Enhancer':\n",
        "    ckpt = '/content/Apollo/model/apollo_model.ckpt'\n",
        "    config = 'configs/apollo.yaml'\n",
        "elif model == 'Lew Vocal Enhancer v2 (beta)':\n",
        "    ckpt = '/content/Apollo/model/apollo_model_v2.ckpt'\n",
        "    config = 'configs/config_apollo_vocal.yaml'\n",
        "elif model == 'Lew Universal Lossy Enhancer':\n",
        "    ckpt = '/content/Apollo/model/apollo_model_uni.ckpt'\n",
        "    config = 'configs/config_apollo_uni.yaml'\n",
        "\n",
        "# --- File Discovery ---\n",
        "supported_extensions = [\"*.wav\", \"*.mp3\", \"*.flac\", \"*.m4a\", \"*.opus\"]\n",
        "audio_files = []\n",
        "for ext in supported_extensions:\n",
        "    search_path = os.path.join(input_directory, ext)\n",
        "    audio_files.extend(glob.glob(search_path))\n",
        "\n",
        "# --- Processing Loop ---\n",
        "if not audio_files:\n",
        "    print(f\"‚ùå No audio files found in '{input_directory}'.\")\n",
        "    print(\"Please upload your files to the correct directory (use the folder icon on the left) and try again.\")\n",
        "else:\n",
        "    total_files = len(audio_files)\n",
        "    print(f\"‚úÖ Found {total_files} audio file(s) to process.\")\n",
        "\n",
        "    for i, input_file in enumerate(audio_files):\n",
        "        file_name = os.path.basename(input_file)\n",
        "        base_name, _ = os.path.splitext(file_name)\n",
        "        output_file = os.path.join(output_directory, f\"{base_name}.wav\")\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"‚ñ∂Ô∏è Processing file {i+1}/{total_files}: {file_name}\")\n",
        "        print(f\"   -> Output will be saved as: {output_file}\")\n",
        "\n",
        "        # Build and execute the command safely\n",
        "        command = (\n",
        "            f\"python inference.py \"\n",
        "            f\"--in_wav {shlex.quote(input_file)} \"\n",
        "            f\"--out_wav {shlex.quote(output_file)} \"\n",
        "            f\"--chunk_size {chunk_size} \"\n",
        "            f\"--overlap {overlap} \"\n",
        "            f\"--ckpt {shlex.quote(ckpt)} \"\n",
        "            f\"--config {shlex.quote(config)}\"\n",
        "        )\n",
        "        \n",
        "        # Using get_ipython().system() to run the shell command\n",
        "        get_ipython().system(command)\n",
        "\n",
        "        print(f\"‚úîÔ∏è Finished processing: {file_name}\")\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"üéâ All {total_files} files have been processed successfully! üéâ\")\n",
        "    print(f\"Check your results in the '{output_directory}' folder.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
